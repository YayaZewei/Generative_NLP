{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo classify images using a reccurent neural network, we consider every image\\nrow as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\\nhandle 28 sequences of 28 steps for every sample.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To classify images using a reccurent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 2\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Permuting batch_size and n_steps\n",
    "x_transpose = tf.transpose(x, [1, 0, 2])\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x_reshape = tf.reshape(x_transpose, [-1, n_input])\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x_nstep = tf.split(0, n_steps, x_reshape)\n",
    "# Define a lstm cell with tensorflow\n",
    "lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "# Get lstm cell output\n",
    "outputs, states = rnn.rnn(lstm_cell, x_nstep, dtype=tf.float32)\n",
    "#the output score\n",
    "pred = tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x.shape\n",
      "(2, 28, 28)\n",
      "x.shape\n",
      "(2, 28, 28)\n",
      "x_transpose.shape\n",
      "(28, 2, 28)\n",
      "x_reshape.shape\n",
      "(56, 28)\n",
      "output\n",
      "0\n",
      "[[  1.37320414e-01   7.82275349e-02   5.95216826e-02   1.50546461e-01\n",
      "    3.57302696e-01  -3.20153415e-01   2.80332327e-01  -5.14831245e-02\n",
      "    1.47666335e-01   1.38003841e-01  -3.64056565e-02   1.30510060e-02\n",
      "    3.13133329e-01  -1.28339101e-02   2.79234946e-01   9.80778597e-03\n",
      "   -1.79315716e-01   4.74456511e-02   2.72651494e-01  -2.54500210e-01\n",
      "    5.32120839e-02  -1.33881420e-02   4.74193037e-01   6.32767528e-02\n",
      "   -1.18695781e-01   1.72720075e-01   1.43118799e-01  -4.67648447e-01\n",
      "    2.07874179e-01  -3.34274232e-01  -1.49666026e-01  -1.56564996e-01\n",
      "   -5.00640236e-02   2.18375660e-02  -4.48620245e-02   9.53665301e-02\n",
      "   -8.08745101e-02  -1.06309792e-02  -2.53331095e-01  -3.20565939e-01\n",
      "   -6.43034130e-02   1.83173910e-01  -1.10994332e-01  -5.83995357e-02\n",
      "    1.10582441e-01  -2.96124518e-01  -3.23962927e-01   3.64838801e-02\n",
      "    1.14526436e-01  -4.79082018e-02  -1.68261737e-01   3.17590714e-01\n",
      "    1.68653011e-01   1.72139645e-01   1.37195393e-01  -2.57148352e-02\n",
      "   -1.05379894e-01   7.24849328e-02  -2.33806804e-01   1.03762269e-01\n",
      "    1.07529550e-03   9.05744731e-03   9.76597220e-02  -1.97286487e-01\n",
      "   -4.86425608e-02   1.88698202e-01  -1.02675647e-01   1.10431150e-01\n",
      "    1.24057688e-01  -1.63994491e-01  -2.57046670e-01   2.43521601e-01\n",
      "   -2.90469304e-02  -1.24458060e-01   2.30801612e-01   1.46115199e-01\n",
      "    5.45420945e-02   2.57845987e-02  -1.88650582e-02   2.82903671e-01\n",
      "   -1.20126538e-01   4.53092664e-01  -2.65931845e-01   6.22795671e-02\n",
      "   -1.42333180e-01   1.53351888e-01   3.90721679e-01   1.80336684e-01\n",
      "    5.62846139e-02  -8.07179883e-02  -8.90034884e-02   2.11863577e-01\n",
      "    1.04093745e-01  -1.40010178e-01   3.49362716e-02   2.60848075e-01\n",
      "   -1.38335302e-01   2.62440369e-03   2.15664253e-01   2.09623381e-01\n",
      "    1.67809516e-01  -4.37784977e-02   7.33657554e-03   6.75298944e-02\n",
      "   -9.55445170e-02   1.75963014e-01  -1.62208736e-01   4.19684798e-02\n",
      "   -1.02119833e-01  -2.65413702e-01   1.32449508e-01  -1.93270117e-01\n",
      "   -5.69069311e-02  -5.85754253e-02   2.84047186e-01   1.28386065e-01\n",
      "    7.80003220e-02  -6.28405735e-02  -3.06987464e-02  -1.54577747e-01\n",
      "    2.71216273e-01  -6.96282387e-02  -4.30884123e-01   1.92135051e-01\n",
      "   -1.01842612e-01   2.39887103e-01   1.01233602e-01   8.26964006e-02]\n",
      " [  2.22912431e-01   2.02022493e-02  -1.70945413e-02   1.70598418e-01\n",
      "    1.10583290e-01  -1.49812683e-01  -8.60388726e-02   1.61745891e-01\n",
      "    1.93551049e-01   1.30590484e-01   2.21516609e-01   1.91680208e-01\n",
      "    3.61766517e-02   1.11524291e-01  -9.39603373e-02   2.00386226e-01\n",
      "    7.07753599e-02   6.59449697e-02   2.66364396e-01  -3.53390090e-02\n",
      "   -2.70347893e-02  -1.00114740e-01   1.70769468e-01  -1.08399689e-01\n",
      "   -1.15058675e-01  -8.75754431e-02  -1.56117186e-01  -3.28503013e-01\n",
      "    1.73391372e-01  -8.21542069e-02  -2.62857795e-01  -1.30950496e-01\n",
      "   -2.74651170e-01  -3.73578966e-02   4.83580716e-02   8.62592161e-02\n",
      "    2.20288709e-02  -6.80200309e-02  -2.50294268e-01  -1.07808702e-01\n",
      "    7.51000643e-02  -3.26863617e-01  -2.97484875e-01  -1.69994801e-01\n",
      "    4.41094041e-02  -3.77640069e-01  -3.87263000e-01   3.26404683e-02\n",
      "   -3.41815837e-02   2.57072877e-03  -3.02426517e-04   1.67297542e-01\n",
      "    3.43082637e-01  -1.19911181e-02  -5.44427857e-02   9.04273167e-02\n",
      "   -2.85043120e-02   8.42747837e-02  -2.27417182e-02  -3.65847461e-02\n",
      "    2.87989303e-02  -7.16173798e-02   9.47728306e-02  -1.68196350e-01\n",
      "   -3.65254790e-01   6.04832880e-02  -6.52322173e-02   8.87679011e-02\n",
      "   -2.19338089e-01  -5.40419891e-02  -1.02868155e-01   2.95933366e-01\n",
      "    1.84699953e-01   1.73136368e-01   2.59270191e-01  -2.76433378e-01\n",
      "    2.52645224e-01   2.63925076e-01  -1.99243069e-01   2.33067334e-01\n",
      "    3.78349843e-03   3.06008402e-02  -2.04606682e-01   1.75997969e-02\n",
      "   -2.24505618e-01   2.46878266e-01   4.12811130e-01  -1.35233980e-02\n",
      "    1.12609565e-01   1.61579877e-01   1.00260973e-01   8.44649374e-02\n",
      "   -1.81591094e-01  -1.79765970e-01   1.20394506e-01  -2.33825948e-02\n",
      "   -7.74220750e-02   1.75503254e-01   7.93512017e-02  -2.44381398e-01\n",
      "    8.47836025e-03   5.46726920e-02  -5.25388196e-02  -8.53034481e-03\n",
      "    4.04367931e-02   3.23082030e-01  -1.13204971e-01  -1.77843198e-01\n",
      "   -9.44460034e-02  -1.28131777e-01   1.37839943e-01  -1.44936338e-01\n",
      "    1.02165997e-01  -2.31483892e-01   1.01484045e-01  -2.41118371e-01\n",
      "   -2.62011260e-01  -9.15082693e-02  -7.30061978e-02  -2.42007077e-01\n",
      "    2.63575137e-01  -6.54452741e-02  -1.16145059e-01   2.00441882e-01\n",
      "   -1.81310579e-01  -1.91630833e-02   2.04372145e-02  -7.97907785e-02]]\n",
      "1\n",
      "[[  6.80744275e-02   3.77287194e-02   3.00407223e-02   7.44127408e-02\n",
      "    1.71725646e-01  -1.60225868e-01   1.35323822e-01  -2.36111600e-02\n",
      "    7.14109540e-02   7.02577233e-02  -1.76359285e-02   6.92696916e-03\n",
      "    1.48117319e-01  -6.21787924e-03   1.29035264e-01   4.95818304e-03\n",
      "   -8.69183987e-02   2.33387370e-02   1.43838912e-01  -1.23032793e-01\n",
      "    2.72332970e-02  -6.57409849e-03   2.21868917e-01   3.30764391e-02\n",
      "   -5.84223419e-02   8.53473693e-02   6.91687837e-02  -2.30241627e-01\n",
      "    1.00948602e-01  -1.50490031e-01  -7.40075111e-02  -7.81455413e-02\n",
      "   -2.36893017e-02   1.12569751e-02  -2.20199805e-02   4.57068346e-02\n",
      "   -4.22985666e-02  -5.22361835e-03  -1.23591118e-01  -1.42987981e-01\n",
      "   -3.22275311e-02   8.87444615e-02  -5.51631078e-02  -2.96965465e-02\n",
      "    5.37775271e-02  -1.48091838e-01  -1.49718717e-01   1.85290687e-02\n",
      "    5.59437908e-02  -2.40560733e-02  -8.39691460e-02   1.54589131e-01\n",
      "    8.74651745e-02   8.90452862e-02   6.80693239e-02  -1.25837494e-02\n",
      "   -5.22608608e-02   3.55856381e-02  -1.15207061e-01   5.05134128e-02\n",
      "    5.49445685e-04   4.31649340e-03   5.07486463e-02  -9.88641232e-02\n",
      "   -2.50064638e-02   9.71292406e-02  -4.89310846e-02   5.28086983e-02\n",
      "    6.33493960e-02  -8.73313323e-02  -1.31650761e-01   1.23526871e-01\n",
      "   -1.47025650e-02  -6.06700294e-02   1.14921302e-01   7.09297210e-02\n",
      "    2.67716404e-02   1.23657314e-02  -9.40729119e-03   1.49049804e-01\n",
      "   -5.77577725e-02   2.09401190e-01  -1.24267250e-01   3.00200731e-02\n",
      "   -6.96733817e-02   7.56143928e-02   1.86464801e-01   9.40443203e-02\n",
      "    2.86357962e-02  -3.94520983e-02  -4.58202921e-02   1.03209160e-01\n",
      "    5.58001474e-02  -6.39614239e-02   1.76109392e-02   1.31601989e-01\n",
      "   -7.61941969e-02   1.19744206e-03   1.08190566e-01   1.07243069e-01\n",
      "    8.60440582e-02  -2.24020593e-02   3.52815678e-03   3.59775126e-02\n",
      "   -4.83335033e-02   8.32812786e-02  -8.14473778e-02   2.09002998e-02\n",
      "   -5.23277223e-02  -1.30923316e-01   7.09195063e-02  -9.45212543e-02\n",
      "   -3.00771687e-02  -2.84670927e-02   1.44763812e-01   6.72179684e-02\n",
      "    3.97556201e-02  -3.08313370e-02  -1.53648611e-02  -7.53576010e-02\n",
      "    1.30742028e-01  -3.33111957e-02  -1.99240252e-01   9.71435830e-02\n",
      "   -5.02068028e-02   1.30452111e-01   5.13490178e-02   4.16214801e-02]\n",
      " [  1.00965068e-01   1.03262989e-02  -9.49736778e-03   8.20856914e-02\n",
      "    5.57454266e-02  -7.16156587e-02  -4.11671139e-02   7.80558661e-02\n",
      "    9.15345773e-02   6.27121404e-02   1.11796767e-01   9.44916978e-02\n",
      "    1.64428577e-02   5.67509755e-02  -4.83443439e-02   9.90953371e-02\n",
      "    3.52158397e-02   3.23166735e-02   1.41926080e-01  -1.91206634e-02\n",
      "   -1.41262868e-02  -5.17858528e-02   8.62318724e-02  -5.54469451e-02\n",
      "   -5.66120967e-02  -4.59117442e-02  -7.94756487e-02  -1.58161864e-01\n",
      "    8.29445198e-02  -4.03129421e-02  -1.30655542e-01  -6.93817139e-02\n",
      "   -1.36905521e-01  -1.86149590e-02   2.35456191e-02   4.27158810e-02\n",
      "    1.12932455e-02  -3.10382042e-02  -1.18902013e-01  -5.16859367e-02\n",
      "    3.71792614e-02  -1.52590394e-01  -1.43914402e-01  -8.84255618e-02\n",
      "    2.23062094e-02  -1.80358261e-01  -1.73594922e-01   1.68756451e-02\n",
      "   -1.79981329e-02   1.28004875e-03  -1.48055595e-04   8.25292617e-02\n",
      "    1.72108412e-01  -5.95987868e-03  -2.80167293e-02   4.23374884e-02\n",
      "   -1.49545474e-02   4.11854088e-02  -1.11765619e-02  -1.82640180e-02\n",
      "    1.47243002e-02  -3.64149660e-02   4.77868542e-02  -8.47496241e-02\n",
      "   -1.77864462e-01   3.27205621e-02  -3.06242518e-02   4.21516597e-02\n",
      "   -1.10335037e-01  -2.80346032e-02  -5.48788644e-02   1.46541506e-01\n",
      "    9.57347527e-02   8.84859636e-02   1.29991502e-01  -1.32277042e-01\n",
      "    1.14763029e-01   1.20681964e-01  -1.00192860e-01   1.11927599e-01\n",
      "    1.82366685e-03   1.51574966e-02  -1.07980780e-01   8.13805219e-03\n",
      "   -1.09418146e-01   1.23671636e-01   2.03609884e-01  -6.88335998e-03\n",
      "    5.75908981e-02   7.91152716e-02   5.33007681e-02   3.94029766e-02\n",
      "   -8.98373574e-02  -8.87966231e-02   5.91430590e-02  -1.25374161e-02\n",
      "   -3.61358970e-02   8.34139436e-02   4.15608436e-02  -1.21684268e-01\n",
      "    4.26627090e-03   2.71719620e-02  -2.56974027e-02  -4.35249275e-03\n",
      "    2.12697014e-02   1.54135644e-01  -5.72505817e-02  -9.11099985e-02\n",
      "   -4.93103713e-02  -6.22114614e-02   7.14779347e-02  -6.94381818e-02\n",
      "    5.20166792e-02  -1.04767695e-01   5.11739701e-02  -1.19526312e-01\n",
      "   -1.22967109e-01  -4.36332189e-02  -3.80903967e-02  -1.23779558e-01\n",
      "    1.30606160e-01  -3.02899871e-02  -5.71815856e-02   9.61933061e-02\n",
      "   -8.62729251e-02  -1.02505721e-02   1.08695338e-02  -3.86256427e-02]]\n",
      "output[-1]\n",
      "[[  6.80744275e-02   3.77287194e-02   3.00407223e-02   7.44127408e-02\n",
      "    1.71725646e-01  -1.60225868e-01   1.35323822e-01  -2.36111600e-02\n",
      "    7.14109540e-02   7.02577233e-02  -1.76359285e-02   6.92696916e-03\n",
      "    1.48117319e-01  -6.21787924e-03   1.29035264e-01   4.95818304e-03\n",
      "   -8.69183987e-02   2.33387370e-02   1.43838912e-01  -1.23032793e-01\n",
      "    2.72332970e-02  -6.57409849e-03   2.21868917e-01   3.30764391e-02\n",
      "   -5.84223419e-02   8.53473693e-02   6.91687837e-02  -2.30241627e-01\n",
      "    1.00948602e-01  -1.50490031e-01  -7.40075111e-02  -7.81455413e-02\n",
      "   -2.36893017e-02   1.12569751e-02  -2.20199805e-02   4.57068346e-02\n",
      "   -4.22985666e-02  -5.22361835e-03  -1.23591118e-01  -1.42987981e-01\n",
      "   -3.22275311e-02   8.87444615e-02  -5.51631078e-02  -2.96965465e-02\n",
      "    5.37775271e-02  -1.48091838e-01  -1.49718717e-01   1.85290687e-02\n",
      "    5.59437908e-02  -2.40560733e-02  -8.39691460e-02   1.54589131e-01\n",
      "    8.74651745e-02   8.90452862e-02   6.80693239e-02  -1.25837494e-02\n",
      "   -5.22608608e-02   3.55856381e-02  -1.15207061e-01   5.05134128e-02\n",
      "    5.49445685e-04   4.31649340e-03   5.07486463e-02  -9.88641232e-02\n",
      "   -2.50064638e-02   9.71292406e-02  -4.89310846e-02   5.28086983e-02\n",
      "    6.33493960e-02  -8.73313323e-02  -1.31650761e-01   1.23526871e-01\n",
      "   -1.47025650e-02  -6.06700294e-02   1.14921302e-01   7.09297210e-02\n",
      "    2.67716404e-02   1.23657314e-02  -9.40729119e-03   1.49049804e-01\n",
      "   -5.77577725e-02   2.09401190e-01  -1.24267250e-01   3.00200731e-02\n",
      "   -6.96733817e-02   7.56143928e-02   1.86464801e-01   9.40443203e-02\n",
      "    2.86357962e-02  -3.94520983e-02  -4.58202921e-02   1.03209160e-01\n",
      "    5.58001474e-02  -6.39614239e-02   1.76109392e-02   1.31601989e-01\n",
      "   -7.61941969e-02   1.19744206e-03   1.08190566e-01   1.07243069e-01\n",
      "    8.60440582e-02  -2.24020593e-02   3.52815678e-03   3.59775126e-02\n",
      "   -4.83335033e-02   8.32812786e-02  -8.14473778e-02   2.09002998e-02\n",
      "   -5.23277223e-02  -1.30923316e-01   7.09195063e-02  -9.45212543e-02\n",
      "   -3.00771687e-02  -2.84670927e-02   1.44763812e-01   6.72179684e-02\n",
      "    3.97556201e-02  -3.08313370e-02  -1.53648611e-02  -7.53576010e-02\n",
      "    1.30742028e-01  -3.33111957e-02  -1.99240252e-01   9.71435830e-02\n",
      "   -5.02068028e-02   1.30452111e-01   5.13490178e-02   4.16214801e-02]\n",
      " [  1.00965068e-01   1.03262989e-02  -9.49736778e-03   8.20856914e-02\n",
      "    5.57454266e-02  -7.16156587e-02  -4.11671139e-02   7.80558661e-02\n",
      "    9.15345773e-02   6.27121404e-02   1.11796767e-01   9.44916978e-02\n",
      "    1.64428577e-02   5.67509755e-02  -4.83443439e-02   9.90953371e-02\n",
      "    3.52158397e-02   3.23166735e-02   1.41926080e-01  -1.91206634e-02\n",
      "   -1.41262868e-02  -5.17858528e-02   8.62318724e-02  -5.54469451e-02\n",
      "   -5.66120967e-02  -4.59117442e-02  -7.94756487e-02  -1.58161864e-01\n",
      "    8.29445198e-02  -4.03129421e-02  -1.30655542e-01  -6.93817139e-02\n",
      "   -1.36905521e-01  -1.86149590e-02   2.35456191e-02   4.27158810e-02\n",
      "    1.12932455e-02  -3.10382042e-02  -1.18902013e-01  -5.16859367e-02\n",
      "    3.71792614e-02  -1.52590394e-01  -1.43914402e-01  -8.84255618e-02\n",
      "    2.23062094e-02  -1.80358261e-01  -1.73594922e-01   1.68756451e-02\n",
      "   -1.79981329e-02   1.28004875e-03  -1.48055595e-04   8.25292617e-02\n",
      "    1.72108412e-01  -5.95987868e-03  -2.80167293e-02   4.23374884e-02\n",
      "   -1.49545474e-02   4.11854088e-02  -1.11765619e-02  -1.82640180e-02\n",
      "    1.47243002e-02  -3.64149660e-02   4.77868542e-02  -8.47496241e-02\n",
      "   -1.77864462e-01   3.27205621e-02  -3.06242518e-02   4.21516597e-02\n",
      "   -1.10335037e-01  -2.80346032e-02  -5.48788644e-02   1.46541506e-01\n",
      "    9.57347527e-02   8.84859636e-02   1.29991502e-01  -1.32277042e-01\n",
      "    1.14763029e-01   1.20681964e-01  -1.00192860e-01   1.11927599e-01\n",
      "    1.82366685e-03   1.51574966e-02  -1.07980780e-01   8.13805219e-03\n",
      "   -1.09418146e-01   1.23671636e-01   2.03609884e-01  -6.88335998e-03\n",
      "    5.75908981e-02   7.91152716e-02   5.33007681e-02   3.94029766e-02\n",
      "   -8.98373574e-02  -8.87966231e-02   5.91430590e-02  -1.25374161e-02\n",
      "   -3.61358970e-02   8.34139436e-02   4.15608436e-02  -1.21684268e-01\n",
      "    4.26627090e-03   2.71719620e-02  -2.56974027e-02  -4.35249275e-03\n",
      "    2.12697014e-02   1.54135644e-01  -5.72505817e-02  -9.11099985e-02\n",
      "   -4.93103713e-02  -6.22114614e-02   7.14779347e-02  -6.94381818e-02\n",
      "    5.20166792e-02  -1.04767695e-01   5.11739701e-02  -1.19526312e-01\n",
      "   -1.22967109e-01  -4.36332189e-02  -3.80903967e-02  -1.23779558e-01\n",
      "    1.30606160e-01  -3.02899871e-02  -5.71815856e-02   9.61933061e-02\n",
      "   -8.62729251e-02  -1.02505721e-02   1.08695338e-02  -3.86256427e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    state = sess.run(states, feed_dict={x: batch_x})\n",
    "    output = sess.run(outputs, feed_dict={x: batch_x})\n",
    "\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "        \n",
    "    print \"Optimization Finished!\"\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
